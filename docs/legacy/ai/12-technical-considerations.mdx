---
title: AI Technical Considerations
created: 2026-02-11
updated: 2026-02-11
---

# AI Technical Considerations

Deep technical analysis of AI system design decisions, trade-offs, and implementation details.

## Table of Contents

1. [Model Registry Architecture](#model-registry-architecture)
2. [Runtime Performance](#runtime-performance)
3. [Cost Management](#cost-management)
4. [Context Window Management](#context-window-management)
5. [Error Handling & Resilience](#error-handling--resilience)
6. [Security & Safety](#security--safety)
7. [Observability](#observability)
8. [State Management](#state-management)

---

## Model Registry Architecture

### Current Schema

```typescript
interface ModelDef {
  id: string;
  name: string;
  provider: string;
  contextWindow: number;
  supportsResponsesV2?: boolean;
  supportsImages?: boolean;
}
```

### Enhanced Schema (Proposed)

```typescript
interface ModelDef {
  // Identity
  id: string;              // e.g., 'anthropic/claude-3.5-sonnet'
  name: string;            // Human-readable name
  provider: string;        // 'anthropic', 'openai', 'google', etc.
  version?: string;        // Model version for tracking

  // Capabilities
  capabilities: {
    functionCalling: boolean;
    vision: boolean;
    audio: boolean;
    streaming: boolean;
    caching: boolean;           // Prompt caching support
    multimodal: string[];       // ['text', 'image', 'audio']
    maxOutputTokens: number;
  };

  // Performance
  performance: {
    contextWindow: number;
    avgLatencyMs: number;        // Estimated P50
    tokensPerSecond: number;     // Streaming speed
    reliabilityScore: number;    // 0-1, from historical data
  };

  // Pricing
  pricing: {
    inputPerMillion: number;
    outputPerMillion: number;
    cachingDiscount?: number;    // 0.5 = 50% off cached tokens
    imageInputCost?: number;     // Per image
  };

  // Suitability scores (0-1, higher is better)
  suitability: {
    creative: number;      // Writing, storytelling
    reasoning: number;     // Planning, analysis
    speed: number;         // Fast iteration
    cost: number;          // Budget-friendly
    structured: number;    // JSON, structured output
  };

  // Operational
  status: 'active' | 'deprecated' | 'beta';
  rateLimit?: {
    requestsPerMinute: number;
    tokensPerMinute: number;
  };
  deprecationDate?: string;
}
```

### Registry Operations

```typescript
class ModelRegistry {
  private models: Map<string, ModelDef>;

  // Find best model for a use case
  selectBestModel(criteria: {
    complexity: OperationComplexity;
    maxCost?: number;
    minSpeed?: number;
    required?: string[];  // Required capabilities
  }): ModelDef {
    const candidates = Array.from(this.models.values())
      .filter(m => m.status === 'active')
      .filter(m => this.meetsRequirements(m, criteria));

    // Score each model
    const scored = candidates.map(m => ({
      model: m,
      score: this.calculateScore(m, criteria),
    }));

    // Return highest scoring
    return scored.sort((a, b) => b.score - a.score)[0]?.model;
  }

  // Calculate composite score
  private calculateScore(model: ModelDef, criteria): number {
    let score = 0;

    switch (criteria.complexity) {
      case 'creative':
        score += model.suitability.creative * 0.7;
        score += model.performance.reliabilityScore * 0.3;
        break;
      case 'complex':
        score += model.suitability.reasoning * 0.8;
        score += model.suitability.cost * 0.2;
        break;
      case 'trivial':
        score += model.suitability.speed * 0.5;
        score += model.suitability.cost * 0.5;
        break;
    }

    // Penalty for high cost if budget constrained
    if (criteria.maxCost) {
      const avgCost = (model.pricing.inputPerMillion + model.pricing.outputPerMillion) / 2;
      if (avgCost > criteria.maxCost) {
        score *= 0.5;
      }
    }

    return score;
  }
}
```

### Registry Persistence

**Storage:** Payload CMS collection `model-registry`

**Update Strategy:**
- Scheduled job fetches latest from OpenRouter `/models` API
- Parse and enrich with our suitability scores
- Cache in memory with 1-hour TTL
- Webhook for manual refresh

---

## Runtime Performance

### Latency Breakdown

Target latency budget (P95):

| Component | Budget | Optimization |
|-----------|--------|-------------|
| **Network (client → server)** | 50ms | CDN, edge functions |
| **Auth & routing** | 10ms | Cached user prefs |
| **Model selection** | 5ms | In-memory registry |
| **OpenRouter overhead** | 100ms | Unavoidable |
| **Model inference** | 200ms | Model choice |
| **Response streaming** | 0ms | Progressive |
| **Total** | **365ms** | Under 500ms target |

### Optimization Techniques

#### 1. Parallel Context Building

```typescript
// Bad: Sequential
const user = await getUser(userId);
const project = await getProject(projectId);
const graph = await getGraph(graphId);
const context = buildContext(user, project, graph);

// Good: Parallel
const [user, project, graph] = await Promise.all([
  getUser(userId),
  getProject(projectId),
  getGraph(graphId),
]);
const context = buildContext(user, project, graph);
```

**Savings:** 150ms → 50ms (3x improvement)

#### 2. Prefetching

```typescript
// On editor mount, prefetch likely contexts
useEffect(() => {
  prefetchContext({
    graphId,
    operations: ['createNode', 'generateDialogue', 'createPlan'],
  });
}, [graphId]);

// When tool is called, context is ready
async function executeTool(tool, args) {
  const context = getCachedContext(tool.name) ?? await buildContext();
  // ...
}
```

#### 3. Streaming Protocol

Use Server-Sent Events (SSE) for progressive rendering:

```typescript
// Server
export async function POST(req: Request) {
  const stream = new ReadableStream({
    async start(controller) {
      const result = await streamText({ ... });

      for await (const chunk of result.textStream) {
        controller.enqueue(`data: ${JSON.stringify({ type: 'text', content: chunk })}\n\n`);
      }

      controller.enqueue(`data: ${JSON.stringify({ type: 'done' })}\n\n`);
      controller.close();
    },
  });

  return new Response(stream, {
    headers: { 'Content-Type': 'text/event-stream' },
  });
}

// Client
const eventSource = new EventSource('/api/assistant');
eventSource.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.type === 'text') {
    appendToMessage(data.content);
  }
};
```

#### 4. Edge Deployment

Deploy `/api/assistant` to Vercel Edge Functions for lower latency:

```typescript
// app/api/assistant/route.ts
export const runtime = 'edge';  // Deploy to edge

export async function POST(req: Request) {
  // Closest region to user
}
```

**Latency improvement:** 200ms → 50ms for global users

---

## Cost Management

### Token Counting

**Problem:** Accurate cost tracking requires token counting before/after requests.

**Solution:** Use `tiktoken` for estimation:

```typescript
import { encoding_for_model } from 'tiktoken';

function estimateTokens(text: string, model: string): number {
  const encoding = encoding_for_model(model);
  const tokens = encoding.encode(text);
  encoding.free();
  return tokens.length;
}

async function estimateCost(messages, model: ModelDef): Promise<number> {
  const inputTokens = messages.reduce((sum, msg) =>
    sum + estimateTokens(msg.content, model.id), 0
  );

  // Assume 2:1 output:input ratio for estimation
  const estimatedOutputTokens = inputTokens * 0.5;

  const cost = (
    (inputTokens * model.pricing.inputPerMillion / 1_000_000) +
    (estimatedOutputTokens * model.pricing.outputPerMillion / 1_000_000)
  );

  return cost;
}
```

### Budget Enforcement

```typescript
interface UserBudget {
  userId: number;
  monthlyLimit: number;  // USD
  currentSpend: number;
  alerts: {
    threshold: number;  // 0.8 = 80%
    notified: boolean;
  }[];
}

async function checkBudget(userId: number, estimatedCost: number): Promise<boolean> {
  const budget = await getUserBudget(userId);

  // Check if within budget
  if (budget.currentSpend + estimatedCost > budget.monthlyLimit) {
    throw new Error('Monthly budget exceeded');
  }

  // Check alert thresholds
  const newTotal = budget.currentSpend + estimatedCost;
  const percentUsed = newTotal / budget.monthlyLimit;

  for (const alert of budget.alerts) {
    if (percentUsed >= alert.threshold && !alert.notified) {
      await sendBudgetAlert(userId, percentUsed);
      alert.notified = true;
    }
  }

  return true;
}
```

### Cost Attribution

Track costs at multiple granularities:

```typescript
interface CostEvent {
  timestamp: Date;
  userId: number;
  projectId?: number;
  editorId?: string;
  toolName: string;
  modelId: string;
  tokensIn: number;
  tokensOut: number;
  cost: number;
  cached: boolean;
  cacheHitRate?: number;
}

// Query examples
async function getCostByDomain(userId: number, month: string) {
  return await db.costEvents.aggregate({
    where: { userId, timestamp: { gte: startOfMonth(month) } },
    by: ['editorId'],
    _sum: { cost: true },
  });
}
```

---

## Context Window Management

### Context Budget Allocation

```typescript
interface ContextBudget {
  total: number;          // Model's max context
  system: number;         // System prompt
  userHistory: number;    // Conversation history
  domainContext: number;  // Graph/character data
  tools: number;          // Tool definitions
  response: number;       // Reserved for output
}

function allocateContextBudget(model: ModelDef): ContextBudget {
  const total = model.performance.contextWindow;

  return {
    total,
    system: Math.min(2000, total * 0.1),
    userHistory: Math.min(4000, total * 0.3),
    domainContext: Math.min(8000, total * 0.4),
    tools: Math.min(2000, total * 0.1),
    response: Math.min(4096, total * 0.1),
  };
}
```

### Context Truncation Strategy

When context exceeds budget:

**Priority order:**
1. **Keep:** System prompt (always)
2. **Keep:** Most recent user message
3. **Keep:** Active tool definitions
4. **Summarize:** Old conversation history (sliding window)
5. **Truncate:** Domain context (graph summary vs full graph)

```typescript
function truncateContext(context, budget: ContextBudget): TruncatedContext {
  let tokens = 0;

  // System prompt (highest priority)
  const system = context.system;
  tokens += estimateTokens(system);

  // Recent messages (sliding window)
  const messages = context.messages.slice(-10);  // Last 10 messages
  tokens += messages.reduce((sum, m) => sum + estimateTokens(m.content), 0);

  // Domain context (adaptive detail)
  let domainTokens = budget.domainContext - tokens;
  const domain = context.domain;

  if (estimateTokens(JSON.stringify(domain)) > domainTokens) {
    // Too large, summarize
    const summary = summarizeDomain(domain, domainTokens);
    return { system, messages, domain: summary };
  }

  return { system, messages, domain };
}
```

### Long-Context Strategies

For models with large context windows (Gemini 1.5 Pro: 1M tokens):

**Use cases:**
- Analyze entire project (all characters + all dialogue)
- Cross-graph consistency checking
- World-building from extensive lore documents

**Cost consideration:**
- Gemini 1.5 Pro: $1.25/M input tokens
- Use sparingly for "analyze everything" operations

---

## Error Handling & Resilience

### Error Classification

```typescript
type ErrorCategory =
  | 'rate_limit'           // 429, backoff and retry
  | 'model_unavailable'    // 503, try fallback model
  | 'context_too_long'     // Truncate and retry
  | 'content_policy'       // 400, different provider
  | 'network'              // Retry with exponential backoff
  | 'auth'                 // 401, refresh token
  | 'budget_exceeded'      // User action required
  | 'unknown';             // Log and surface to user

function classifyError(error: any): ErrorCategory {
  if (error.status === 429) return 'rate_limit';
  if (error.status === 503) return 'model_unavailable';
  if (error.code === 'context_length_exceeded') return 'context_too_long';
  if (error.message?.includes('content_policy')) return 'content_policy';
  // ...
  return 'unknown';
}
```

### Retry Strategy

```typescript
async function executeWithRetry(fn: () => Promise<any>, options = {}) {
  const {
    maxRetries = 3,
    baseDelay = 1000,
    maxDelay = 10000,
  } = options;

  for (let attempt = 0; attempt < maxRetries; attempt++) {
    try {
      return await fn();
    } catch (error) {
      const category = classifyError(error);

      // Don't retry these
      if (['auth', 'budget_exceeded', 'content_policy'].includes(category)) {
        throw error;
      }

      // Retry with fallback
      if (category === 'model_unavailable') {
        // Try fallback model
        return await executeWithFallback(fn);
      }

      // Exponential backoff
      const delay = Math.min(baseDelay * Math.pow(2, attempt), maxDelay);
      await sleep(delay);
    }
  }

  throw new Error('Max retries exceeded');
}
```

### Circuit Breaker

Prevent cascading failures:

```typescript
class CircuitBreaker {
  private failures = 0;
  private lastFailure = 0;
  private state: 'closed' | 'open' | 'half-open' = 'closed';

  async execute<T>(fn: () => Promise<T>): Promise<T> {
    if (this.state === 'open') {
      if (Date.now() - this.lastFailure > 60000) {  // 1 min cooldown
        this.state = 'half-open';
      } else {
        throw new Error('Circuit breaker open');
      }
    }

    try {
      const result = await fn();
      this.onSuccess();
      return result;
    } catch (error) {
      this.onFailure();
      throw error;
    }
  }

  private onSuccess() {
    this.failures = 0;
    this.state = 'closed';
  }

  private onFailure() {
    this.failures++;
    this.lastFailure = Date.now();

    if (this.failures >= 5) {
      this.state = 'open';
    }
  }
}

// Per-model circuit breakers
const breakers = new Map<string, CircuitBreaker>();

async function callModel(modelId: string, params) {
  const breaker = breakers.get(modelId) ?? new CircuitBreaker();
  breakers.set(modelId, breaker);

  return await breaker.execute(() => actualModelCall(modelId, params));
}
```

---

## Security & Safety

### Prompt Injection Detection

```typescript
const INJECTION_PATTERNS = [
  /ignore previous instructions/i,
  /new instructions:/i,
  /system prompt:/i,
  /you are now/i,
  /\[SYSTEM\]/i,
];

function detectInjection(userInput: string): boolean {
  return INJECTION_PATTERNS.some(pattern => pattern.test(userInput));
}

async function executeTool(tool, args) {
  // Check all string arguments
  for (const [key, value] of Object.entries(args)) {
    if (typeof value === 'string' && detectInjection(value)) {
      throw new Error('Potential prompt injection detected');
    }
  }

  return await tool.execute(args);
}
```

### Output Validation

```typescript
interface OutputValidator {
  validate(output: string): ValidationResult;
}

class ContentPolicyValidator implements OutputValidator {
  private bannedPatterns = [
    // PII patterns
    /\b\d{3}-\d{2}-\d{4}\b/,  // SSN
    /\b\d{16}\b/,             // Credit card
    // NSFW patterns
    // ...
  ];

  validate(output: string): ValidationResult {
    for (const pattern of this.bannedPatterns) {
      if (pattern.test(output)) {
        return {
          valid: false,
          reason: 'Content policy violation',
        };
      }
    }

    return { valid: true };
  }
}
```

### Rate Limiting

Per-user, per-tier limits:

```typescript
interface RateLimit {
  tier: 'free' | 'pro' | 'enterprise';
  limits: {
    requestsPerMinute: number;
    requestsPerDay: number;
    tokensPerDay: number;
  };
}

const RATE_LIMITS: Record<string, RateLimit> = {
  free: {
    tier: 'free',
    limits: {
      requestsPerMinute: 5,
      requestsPerDay: 100,
      tokensPerDay: 50_000,
    },
  },
  pro: {
    tier: 'pro',
    limits: {
      requestsPerMinute: 30,
      requestsPerDay: 1000,
      tokensPerDay: 1_000_000,
    },
  },
};
```

---

## Observability

### Structured Logging

```typescript
interface LogEvent {
  level: 'debug' | 'info' | 'warn' | 'error';
  timestamp: Date;
  userId?: number;
  requestId: string;
  component: string;
  event: string;
  metadata?: Record<string, any>;
  duration?: number;
  error?: Error;
}

function logToolExecution(tool, args, result, duration) {
  logger.info({
    component: 'tool-executor',
    event: 'tool_executed',
    metadata: {
      toolName: tool.name,
      domain: tool.domain,
      argsSize: JSON.stringify(args).length,
      resultSize: JSON.stringify(result).length,
    },
    duration,
  });
}
```

### Metrics Collection

```typescript
interface Metrics {
  // Counters
  incr(metric: string, tags?: Record<string, string>): void;

  // Gauges
  gauge(metric: string, value: number, tags?: Record<string, string>): void;

  // Histograms
  histogram(metric: string, value: number, tags?: Record<string, string>): void;

  // Timers
  timing(metric: string, duration: number, tags?: Record<string, string>): void;
}

// Usage
metrics.incr('tool.execute', { tool: 'forge_createNode', model: 'gpt-4o-mini' });
metrics.timing('tool.latency', duration, { tool: 'forge_createNode' });
metrics.gauge('user.tokens_remaining', tokensRemaining, { userId: user.id });
```

---

## State Management

### Tool Execution State

```typescript
type ExecutionState =
  | { status: 'idle' }
  | { status: 'executing', tool: string, startedAt: Date }
  | { status: 'streaming', tool: string, progress: number }
  | { status: 'success', result: any, duration: number }
  | { status: 'error', error: Error };

// Zustand store
interface AssistantStore {
  executionState: ExecutionState;
  setExecutionState: (state: ExecutionState) => void;

  // History
  executionHistory: ExecutionRecord[];
  addToHistory: (record: ExecutionRecord) => void;
}
```

### Context Synchronization

Keep domain state and AI context in sync:

```typescript
// When graph changes
onGraphChange((graph) => {
  // Update domain context
  updateDomainContext({
    domain: 'forge',
    snapshot: buildForgeContext({ graph }),
  });
});

// AI reads latest context
async function executeTool(tool, args) {
  const context = getDomainContext(tool.domain);
  return await tool.execute(args, context);
}
```

---

## References

- [Model Strategy](./10-model-strategy.mdx)
- [AI Roadmap](./11-ai-roadmap.mdx)
- [Cost Optimization](./13-cost-optimization.mdx)
- [Runtime Implementation](./04-runtime-and-components.mdx)
