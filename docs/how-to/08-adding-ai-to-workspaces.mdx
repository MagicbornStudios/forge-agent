---
title: 08 - Adding AI to modes

created: 2026-02-04
updated: 2026-02-07
---

# 08 - Adding AI to modes

How to add more AI to the app: domain actions, app-level actions, agents, and (future) graphs/subgraphs. Single source of truth for architecture: [architecture/03-copilotkit-and-agents.mdx](../architecture/03-copilotkit-and-agents.mdx).

## Overview

- **One CopilotKit provider**, one **OpenRouter** agent today. Model is resolved per request (model router or override).
- **Context** = shell (AppShell) + active domain contract when a mode is mounted.
- **Actions** = shell + domain (`forge_` / `video_`) + app-level (`app_`). Use helper factories to prefix consistently.

## Adding domain actions

1. Implement or extend a **DomainCopilotContract** ([packages/shared/src/shared/copilot/types.ts](../../packages/shared/src/shared/copilot/types.ts)): `getContextSnapshot()`, `getInstructions()`, `createActions()`, `getSuggestions()`, `onAIHighlight` / `clearAIHighlights`.
2. In the mode component, call **useDomainCopilot(contract, { toolsEnabled })**. Only one mode is mounted at a time, so only that domain's actions are active.
3. Build action configs with `createDomainAction('forge', config)` (or your domain id). This keeps names consistent.
4. **References:** Dialogue = [packages/domain-forge/src/copilot](../../packages/domain-forge/src/copilot), Video = [apps/studio/lib/domains/video/copilot](../../apps/studio/lib/domains/video/copilot).

Step-by-step: [14-adding-domain-actions.mdx](../14-adding-domain-actions.mdx).

## Adding app-level actions

1. Register in [AppShell.tsx](../../apps/studio/components/AppShell.tsx) with **useCopilotAction** using `createAppAction(...)` (adds the `app_` prefix).
2. Handler can call internal APIs (e.g. `/api/image-generate`, `/api/structured-output`). Optional **render** for chat UI; must return a **ReactElement** (no `null` -- use `<></>` as fallback).
3. Gate by capability (e.g. `CAPABILITIES.IMAGE_GENERATION`) and pass **available: 'disabled'** when the feature is off.

## Agents

- **Today:** Single agent in [apps/studio/app/api/copilotkit/route.ts](../../apps/studio/app/api/copilotkit/route.ts) (OpenRouter).
- **Next.js wrapper:** `@forge/shared/copilot/next` exports `ForgeCopilotProvider` + `createForgeCopilotRuntime(...)` for fast adoption.
- **Adding another agent** (e.g. co-agent per mode): see [17-co-agents-and-multi-agent.mdx](../17-co-agents-and-multi-agent.mdx). No code changes in this guide.

## Workflow graphs (internal engine)

- **Now:** We have a minimal workflow engine in `packages/agent-engine` (steps + events) and a streaming endpoint `POST /api/workflows/run` that emits plan/patch/review over SSE. This is the base pattern for plan -> propose -> review workflows.
- **Later:** If we add LangGraph, it replaces the workflow executor, not the domain contracts. This keeps the client wiring stable.

## Conventions recap

- One contract per domain; use `createDomainAction()` / `createAppAction()` to prefix consistently.
- Same number of actions every render; use **available: 'disabled'** when an action is contextually inactive.
- **OpenRouter** is the model provider for chat, image gen, and structured output. **Provider stack:** OpenRouter = text + image; ElevenLabs = TTS (character voices); video = OpenAI Sora when we add it. See [06 - Model routing and OpenRouter](../architecture/06-model-routing-and-openrouter.mdx).

## Character voice (ElevenLabs)

Character voice selection + preview uses **ElevenLabs** (TTS). Configure `ELEVENLABS_API_KEY` in the Studio environment. The Character create/edit forms expose a voice dropdown and a preview play button that call `/api/elevenlabs/voices` and `/api/elevenlabs/speech`.

**Next:** Back to [00 - Index](00-index.md) or [07 - Copilot and AI integration](07-copilot.md).
